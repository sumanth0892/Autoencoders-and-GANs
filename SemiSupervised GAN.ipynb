{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from keras import backend as K \n",
    "from keras.datasets import mnist \n",
    "from keras.layers import (#Import the necessary layers here)\n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from keras.optimizers import Adam \n",
    "from keras.models import Model,Sequential \n",
    "from keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model input dimensions \n",
    "imgRows = 28\n",
    "imgCols = 28\n",
    "channels = 1\n",
    "imgShape = (imgRows,imgCols,channels)\n",
    "zDim = 100\n",
    "nClasses = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self,nLabeled):\n",
    "        self.nLabeled = nLabeled \n",
    "        (self.x_train,self.y_train),(self.x_test,self.y_test) = mnist.load_data()\n",
    "    \n",
    "    def preProcessImgs(x):\n",
    "        x = (x.astype(np.float32) - 127.5)/127.5\n",
    "        x = np.expand_dims(x,axis = 3)\n",
    "        return x \n",
    "    \n",
    "    def preProcessLabels(y):\n",
    "        return y.reshape(-1,1)\n",
    "    \n",
    "    self.x_train = preProcessImgs(self.x_train)\n",
    "    self.x_test = preProcessImgs(self.x_test)\n",
    "    self.y_train = preProcessLabels(self.y_train)\n",
    "    self.y_test = preProcessLabels(self.y_test)\n",
    "    \n",
    "    def batchLabeled(self,batch_size):\n",
    "        idx = np.random.randint(0,self.nLabeled,batch_size)\n",
    "        imgs = self.x_train[idx]\n",
    "        labels = self.y_train[idx]\n",
    "        return imgs,labels\n",
    "    \n",
    "    def batchUnlabeled(self,batch_size):\n",
    "        idx = np.random.randint(self.nLabeled,self.x_train.shape[0],batch_size)\n",
    "        imgs = self.x_train[idx]\n",
    "        return imgs \n",
    "    \n",
    "    def training_set(self):\n",
    "        x_train = self.x_train[range(self.nLabeled)]\n",
    "        y_train = self.y_train[range(self.nLabeled)]\n",
    "        return x_train,y_train \n",
    "    \n",
    "    def test_set(self):\n",
    "        return self.x_test,self.y_test\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildGenerator(zDim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(7*7*256,input_dim = zDim))\n",
    "    model.add(Reshape((7,7,256)))\n",
    "    model.add(Conv2DTranspose(128,kernel_size = 3,strides = 2,padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Conv2DTranspose(64,kernel_size = 3,strides = 1,padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Conv2DTranspose(1,kernel_size = 3,strides = 2,padding = 'same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDiscriminator_net(imgShape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,kernel_size = 3,strides = 2,padding = 'same',input_shape = imgShape))\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Conv2D(64,kernel_size = 3,strides = 2,padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Conv2D(128,kernel_size = 3,strides = 2,padding = 'same'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nClasses))\n",
    "    return model \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminatorSupervised(D):\n",
    "    #The discriminator to build the supervised part of the training \n",
    "    model = Sequential()\n",
    "    model.add(D)\n",
    "    model.add(Activation('softmax'))\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    prediction = 1.0 - (1.0/(K.sum(K.exp(x),axis = -1,keepdims = True)+1.0))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminatorUnsupervised(D):\n",
    "    #Unsupervised part of the training \n",
    "    model = Sequential()\n",
    "    model.add(D)\n",
    "    model.add(Lambda(predict))\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildGAN(G,D):\n",
    "    model = Sequential()\n",
    "    model.add(G)\n",
    "    model.add(D)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNet = buildDiscriminator_net(imgShape)\n",
    "DSupervised = discriminatorSupervised(DNet)\n",
    "DSupervised.compile(loss = 'categorical_crossentropy',optimizer = Adam(),metrics = ['accuracy'])\n",
    "DUnsupervised = discriminatorUnsupervised(DNet)\n",
    "DUnsupervised.compile(loss = 'binary_crossentropy',optimizer = Adam())\n",
    "Generator = buildGenerator(zDim)\n",
    "DUnsupervised.trainable = False \n",
    "SGAN = buildGAN(Generator,DUnsupervised)\n",
    "SGAN.compile(loss = 'binary_crossentropy',optimizer = Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_losses = []; accuracies = []\n",
    "nLabeled = 100 #Mini-batch size \n",
    "#Get the labeled and unlabeled images\n",
    "dataset = Dataset(nLabeled)\n",
    "def trainGAN(iterations,batch_size,sampleInterval):\n",
    "    real = np.ones((batch_size,1))\n",
    "    fake = np.zeros((batch_size,1))\n",
    "    for iteration in range(iterations):\n",
    "        #Get a batch of Both labeled and unlabeled images\n",
    "        imgs,labels = dataset.batchLabeled(batch_size)\n",
    "        labels = to_categorical(labels,nClasses)\n",
    "        imgsUnlabeled = dataset.batchUnlabeled(batch_size)\n",
    "        \n",
    "        #Train the Supervised discriminator \n",
    "        z = np.random.normal(0,1,(batch_size,zDim))\n",
    "        genImgs = generator.predict(z)\n",
    "        dLossSupervised,accuracy = DSupervised.train_on_batch(imgs,labels)\n",
    "        \n",
    "        #Train the unsupervised discriminator \n",
    "        dLossReal = DUnsupervised.train_on_batch(imgsUnlabeled,real)\n",
    "        dLossFake = DUnsupervised.train_on_batch(genImgs,fake)\n",
    "        dLossUnsupervised = 0.5*np.add(dLossReal,dLossFake)\n",
    "        \n",
    "        #Train the generator\n",
    "        z = np.random.normal(0,1,(batch_size,zDim))\n",
    "        genImgs = generator.predict(z)\n",
    "        gLoss = generator.train_on_batch(z,np.ones((batch_size,1)))\n",
    "        \n",
    "        if(iteration+1)%sampleInterval == 0:\n",
    "            supervised_losses.append(dLossSupervised)\n",
    "            accuracies.append(accuracy)\n",
    "            \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
